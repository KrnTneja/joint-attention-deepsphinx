#!/home/karan/tfvenv/bin/python
# vim: filetype=python

'''Script for training the model'''
import time
import os
import tensorflow as tf
from tensorflow.python import debug as tf_debug
from deepsphinx.seq2seq_model import seq2seq_model
from deepsphinx.data import read_data_queue, get_speaker_stats
from deepsphinx.vocab import VOCAB, VOCAB_INF
from deepsphinx.utils import wer, FLAGS
from deepsphinx.flags import load_flags
try:
    import pywrapfst as fst
except ImportError:
    tf.logging.info("pywrapfst does not exist, ignoring")
    pass

# if FLAGS.cuda_visible_devices:
#     import os
#     os.environ["CUDA_VISIBLE_DEVICES"]=FLAGS.cuda_visible_devices

def run_eval(graph,
             queue,
             predictions,
             outputs,
             output_lengths,
             step,
             cost,
             keep_prob_tensor,
             mean_speaker,
             var_speaker,
             lm_fst):
    '''Evaluate with eval dataset'''

    tf.logging.info('Evaluation started')
    with graph.as_default():
        writer = tf.summary.FileWriter(FLAGS.job_dir)
        tf.Session.reset(None, ['queue'])

        config = tf.ConfigProto()
        config.gpu_options.allow_growth=True
        with tf.Session(config=config) as sess:
            # sess = tf_debug.LocalCLIDebugWrapperSession(sess)
            # sess = tf_debug.TensorBoardDebugWrapperSession(sess, 'localhost:6064')

        # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)
        # with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:

            tf.train.Saver().restore(sess, FLAGS.checkpoint_path)
            read_data_queue('eval',
                            queue,
                            sess,
                            mean_speaker,
                            var_speaker,
                            lm_fst)
            tot_per = 0.0
            batch_loss = 0.0
            tot_ev = 0
            tot_bat = 0
            coord = tf.train.Coordinator(
                clean_stop_exception_types=(
                    tf.errors.CancelledError,
                    tf.errors.OutOfRangeError))

            with coord.stop_on_exception():
                while not coord.should_stop():
                    pred, out, out_len, loss = sess.run(
                        [predictions, outputs, output_lengths, cost],
                        feed_dict={keep_prob_tensor: 1.0})
                    tot_ev += pred.shape[0]
                    tot_bat += 1
                    batch_loss += loss
                    for i in range(pred.shape[0]):
                        best_per = 100.0
                        if FLAGS.inflection_task:
                            if FLAGS.use_joint_prob:                            
                                    real_out = [VOCAB_INF[l] for l in out[i, :out_len[i] - 1]]
                                    pred_out = [VOCAB_INF[l] for l in pred[i, :]]
                                    if '</s>' in pred_out: pred_out = pred_out[:pred_out.index('</s>')]
                                    cur_per = wer(real_out, pred_out)
                                    tot_per += cur_per
                            else:
                                for j in range(FLAGS.best_n_inference):
                                    real_out = [VOCAB_INF[l] for l in out[i, :out_len[i] - 1]]
                                    pred_out = [VOCAB_INF[l] for l in pred[i, :, j]]
                                    if '</s>' in pred_out: pred_out = pred_out[:pred_out.index('</s>')]
                                    cur_per = wer(real_out, pred_out)
                                    best_per = min(best_per, cur_per)
                                tot_per += best_per
                        else:
                            if FLAGS.use_joint_prob:                            
                                real_out = [VOCAB[l] for l in out[i, :out_len[i] - 1]]
                                pred_out = [VOCAB[l] for l in pred[i, :]]
                                if '</s>' in pred_out: pred_out = pred_out[:pred_out.index('</s>')]
                                cur_per = wer(real_out, pred_out)
                                tot_per += cur_per
                            else:
                                for j in range(FLAGS.best_n_inference):
                                    real_out = [VOCAB[l] for l in out[i, :out_len[i] - 1]]
                                    pred_out = [VOCAB[l] for l in pred[i, :, j]]
                                    if '</s>' in pred_out: pred_out = pred_out[:pred_out.index('</s>')]
                                    cur_per = wer(real_out, pred_out)
                                    best_per = min(best_per, cur_per)
                                tot_per += best_per

            if tot_ev > 0:
                tf.logging.info('PER: {}'.format(
                    tot_per / tot_ev))
                summary = tf.Summary(
                    value=[tf.Summary.Value(tag='PER_valid', simple_value=tot_per / tot_ev),
                           tf.Summary.Value(tag='loss_valid', simple_value=batch_loss / tot_bat)
                          ])
                writer.add_summary(summary, global_step=sess.run(step))
                writer.flush()
            coord.request_stop()
    tf.logging.info('Evaluation finished')


def train(_):
    '''Train the model and evaluate at every epoch'''
    checkpoint = os.path.join(FLAGS.job_dir, 'checkpoints/')

    if FLAGS.eval_only:
        sets = ['eval']
    else:
        sets = ['eval', 'train']

    if FLAGS.use_train_lm or FLAGS.use_inference_lm:
        lm_fst = fst.Fst.read_from_string(tf.gfile.FastGFile(FLAGS.fst_path, 'rb').read())
    else:
        lm_fst = None


    graph = tf.Graph()
    with graph.as_default():
        learning_rate_tensor = tf.placeholder(
            tf.float32,
            name='learning_rate')
        keep_prob_tensor = tf.placeholder(
            tf.float32,
            name='keep_prob')
        # https://stackoverflow.com/questions/39204335/can-a-tensorflow-queue-be-reopened-after-it-is-closed
        with tf.container('queue'):
            if FLAGS.inflection_task:
                queue = tf.PaddingFIFOQueue(
                    capacity=64,
                    dtypes=['float32', 'int32', 'int32', 'int32'],
                    shapes=[[None, 26+9], [], [None], []],
                    name='feed_queue')
            else:
                queue = tf.PaddingFIFOQueue(
                    capacity=64,
                    dtypes=['float32', 'int32', 'int32', 'int32'],
                    shapes=[[None, FLAGS.nfilt * 3 + 1], [], [None], []],
                    name='feed_queue')
            inputs, input_lengths, outputs, output_lengths = queue.dequeue_many(
                FLAGS.batch_size)

        if FLAGS.use_joint_prob:
            training_logits, predictions, train_op, cost, step, target_lengths, beam_probs_history, beam_alignments_length = seq2seq_model(
                inputs,
                outputs,
                input_lengths,
                output_lengths,
                lm_fst,
                keep_prob_tensor)
        else:
            training_logits, predictions, train_op, cost, step = seq2seq_model(
                inputs,
                outputs,
                input_lengths,
                output_lengths,
                lm_fst,
                keep_prob_tensor)

        writer = tf.summary.FileWriter(FLAGS.job_dir, graph=graph)
        saver = tf.train.Saver()
        batch_loss = 0.0
        writer.add_graph(graph)

        if FLAGS.inflection_task:
            mean_speaker, var_speaker = 0, 0
        else:
            mean_speaker, var_speaker = get_speaker_stats(sets)
        tf.logging.info('Starting training')

        for epoch_i in range(1, FLAGS.num_epochs + 1):
            if (FLAGS.checkpoint_path is not None):
                run_eval(graph,
                         queue,
                         predictions,
                         outputs,
                         output_lengths,
                         step,
                         cost,
                         keep_prob_tensor,
                         mean_speaker,
                         var_speaker,
                         lm_fst)
            if FLAGS.eval_only:
                break
            tf.Session.reset(None, ['queue'])
            config = tf.ConfigProto()
            config.gpu_options.allow_growth=True
            with tf.Session(config=config) as sess:
                # sess = tf_debug.TensorBoardDebugWrapperSession(sess, 'localhost:6064')                
                # sess = tf_debug.LocalCLIDebugWrapperSession(sess)

                coord = tf.train.Coordinator(
                    clean_stop_exception_types=(
                        tf.errors.CancelledError,
                        tf.errors.OutOfRangeError))
                if (FLAGS.checkpoint_path is None):
                    sess.run(tf.global_variables_initializer())
                    sess.run(tf.local_variables_initializer())
                    last_display_step = 0
                else:
                    print("checkpoint_path:", FLAGS.checkpoint_path)
                    saver.restore(sess, FLAGS.checkpoint_path)
                    last_display_step = sess.run(step)

                read_data_queue('train',
                                queue,
                                sess,
                                mean_speaker,
                                var_speaker,
                                lm_fst)

                with coord.stop_on_exception():
                    while not coord.should_stop():
                        start_time = time.time()
                        
                        if FLAGS.use_joint_prob:
                            # loss, _, batch_i, batch_target_lengths, batch_beam_probs_history, alignments_length, out, out_len = sess.run(
                            #     [cost, train_op, step, target_lengths, beam_probs_history, beam_alignments_length,
                            #         outputs, output_lengths],    # Replaced predictions with None to avoid running inference - 02/05/2018 
                            #     feed_dict={learning_rate_tensor: FLAGS.learning_rate,
                            #                keep_prob_tensor: FLAGS.keep_prob})
                            # Un-Commented to NOT avoid running inference - 02/05/2018
                            loss, _, batch_i, batch_target_lengths, batch_beam_probs_history, alignments_length, pred, out, out_len = sess.run(
                                [cost, train_op, step, target_lengths, beam_probs_history, beam_alignments_length,
                                    predictions, outputs, output_lengths],     
                                feed_dict={learning_rate_tensor: FLAGS.learning_rate,
                                           keep_prob_tensor: FLAGS.keep_prob})
                        else:
                            loss, _, batch_i, pred, out, out_len = sess.run(
                                [cost, train_op, step, predictions, outputs, output_lengths],
                                feed_dict={learning_rate_tensor: FLAGS.learning_rate,
                                           keep_prob_tensor: FLAGS.keep_prob})

                        batch_loss += loss
                        end_time = time.time()
                        batch_time = end_time - start_time

                        if batch_i % FLAGS.display_step == 0 and batch_i - last_display_step > 0:
                            tf.logging.info('Epoch {:>3}/{} Batch {:>4} - Loss: {:>6.3f}, Seconds: {:>4.2f}'
                                            .format(epoch_i,
                                                    FLAGS.num_epochs,
                                                    batch_i,
                                                    batch_loss / (batch_i - last_display_step),
                                                    batch_time))
                            tot_per = 0.0

                            # pred, out, out_len = sess.run(
                            #     [predictions, outputs, output_lengths],
                            #     feed_dict={keep_prob_tensor: 1.0})
                            if FLAGS.inflection_task:
                                for i in range(pred.shape[0]):
                                    print(pred.shape)
                                    if FLAGS.use_joint_prob:
                                        real_out = [VOCAB_INF[l] for l in out[i, :out_len[i] - 1]]
                                        pred_out = [VOCAB_INF[l] for l in pred[i, :]]
                                    else:
                                        real_out = [VOCAB_INF[l] for l in out[i, :out_len[i] - 1]]
                                        pred_out = [VOCAB_INF[l] for l in pred[i, :, 0]]
                                    if '</s>' in pred_out: pred_out = pred_out[:pred_out.index('</s>')]
                                    tot_per += wer(real_out, pred_out)
                            else:
                                for i in range(pred.shape[0]):
                                    if FLAGS.use_joint_prob:
                                        real_out = [VOCAB[l] for l in out[i, :out_len[i] - 1]]
                                        pred_out = [VOCAB[l] for l in pred[i, :]]
                                    else:
                                        real_out = [VOCAB[l] for l in out[i, :out_len[i] - 1]]
                                        pred_out = [VOCAB[l] for l in pred[i, :, 0]]
                                    if '</s>' in pred_out: pred_out = pred_out[:pred_out.index('</s>')]
                                    tot_per += wer(real_out, pred_out)
                            tf.logging.info(
                                'Sample real output: {}'.format(real_out))
                            tf.logging.info(
                                'Sample predicted output: {}'.format(pred_out))
                            tf.logging.info('PER: {}'.format(
                                tot_per / pred.shape[0]))
                            summary = tf.Summary(value=[
                                tf.Summary.Value(
                                    tag='PER', simple_value=tot_per / pred.shape[0]),
                                tf.Summary.Value(
                                    tag='loss',
                                    simple_value=batch_loss / (batch_i - last_display_step))
                                ])
                            last_display_step = batch_i
                            writer.add_summary(summary, global_step=batch_i)
                            writer.flush()
                            batch_loss = 0.0

                        # Reduce learning rate, but not below its minimum value
                        FLAGS.learning_rate *= FLAGS.learning_rate_decay
                        if FLAGS.learning_rate < FLAGS.min_learning_rate:
                            FLAGS.learning_rate = FLAGS.min_learning_rate

                tf.logging.info('Epoch completed, saving')
                FLAGS.checkpoint_path = saver.save(
                    sess, checkpoint + 'batch', step)

                coord.request_stop()


if __name__ == '__main__':
    tf.logging.set_verbosity(tf.logging.INFO)
    load_flags()
    tf.app.run(train)
